{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZ0594t1tZO18aDvss/YYS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMnOu8H4ITwX","executionInfo":{"status":"ok","timestamp":1740475502768,"user_tz":-330,"elapsed":11627,"user":{"displayName":"Amanchi Chandana","userId":"09488927442165634315"}},"outputId":"108386b4-1fe7-4e4c-dc80-8fea78366c57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['Setup_Time_Violations', 'Hold_Time_Violations', 'Critical_Path_Delay',\n","       'Propagation_Delay', 'Clock_Skew', 'Clock_Domain_Crossings',\n","       'Fan_In_Count', 'Fan_Out_Count', 'Combinational_Logic_Levels',\n","       'Pipeline_Stages', 'Register_to_Register_Path_Length',\n","       'Multiplexer_Depth', 'Gate_Count', 'Logic_Optimization_Ratio',\n","       'Resource_Utilization', 'Retiming_Factor', 'Clock_Gating_Ratio',\n","       'Combinational_Depth', 'Timing_Violation_Probability'],\n","      dtype='object')\n","Epoch 1/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.4772 - mae: 0.7187 - val_loss: 0.9423 - val_mae: 0.3881 - learning_rate: 5.0000e-04\n","Epoch 2/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1012 - mae: 0.5030 - val_loss: 0.8547 - val_mae: 0.3372 - learning_rate: 5.0000e-04\n","Epoch 3/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9917 - mae: 0.4431 - val_loss: 0.8053 - val_mae: 0.3116 - learning_rate: 5.0000e-04\n","Epoch 4/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9199 - mae: 0.4051 - val_loss: 0.7706 - val_mae: 0.2956 - learning_rate: 5.0000e-04\n","Epoch 5/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8548 - mae: 0.3703 - val_loss: 0.7398 - val_mae: 0.2854 - learning_rate: 5.0000e-04\n","Epoch 6/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8048 - mae: 0.3503 - val_loss: 0.7145 - val_mae: 0.2807 - learning_rate: 5.0000e-04\n","Epoch 7/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7681 - mae: 0.3369 - val_loss: 0.6906 - val_mae: 0.2768 - learning_rate: 5.0000e-04\n","Epoch 8/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7383 - mae: 0.3269 - val_loss: 0.6666 - val_mae: 0.2729 - learning_rate: 5.0000e-04\n","Epoch 9/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7221 - mae: 0.3259 - val_loss: 0.6431 - val_mae: 0.2685 - learning_rate: 5.0000e-04\n","Epoch 10/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7019 - mae: 0.3254 - val_loss: 0.6223 - val_mae: 0.2669 - learning_rate: 5.0000e-04\n","Epoch 11/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6425 - mae: 0.2853 - val_loss: 0.6023 - val_mae: 0.2655 - learning_rate: 5.0000e-04\n","Epoch 12/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6418 - mae: 0.3075 - val_loss: 0.5823 - val_mae: 0.2637 - learning_rate: 5.0000e-04\n","Epoch 13/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6077 - mae: 0.2901 - val_loss: 0.5632 - val_mae: 0.2625 - learning_rate: 5.0000e-04\n","Epoch 14/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5796 - mae: 0.2796 - val_loss: 0.5453 - val_mae: 0.2616 - learning_rate: 5.0000e-04\n","Epoch 15/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5523 - mae: 0.2653 - val_loss: 0.5270 - val_mae: 0.2601 - learning_rate: 5.0000e-04\n","Epoch 16/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5434 - mae: 0.2758 - val_loss: 0.5100 - val_mae: 0.2598 - learning_rate: 5.0000e-04\n","Epoch 17/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5201 - mae: 0.2711 - val_loss: 0.4932 - val_mae: 0.2588 - learning_rate: 5.0000e-04\n","Epoch 18/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5032 - mae: 0.2616 - val_loss: 0.4778 - val_mae: 0.2588 - learning_rate: 5.0000e-04\n","Epoch 19/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4890 - mae: 0.2696 - val_loss: 0.4621 - val_mae: 0.2579 - learning_rate: 5.0000e-04\n","Epoch 20/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4668 - mae: 0.2592 - val_loss: 0.4467 - val_mae: 0.2565 - learning_rate: 5.0000e-04\n","Epoch 21/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4596 - mae: 0.2681 - val_loss: 0.4318 - val_mae: 0.2552 - learning_rate: 5.0000e-04\n","Epoch 22/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4340 - mae: 0.2508 - val_loss: 0.4178 - val_mae: 0.2544 - learning_rate: 5.0000e-04\n","Epoch 23/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4177 - mae: 0.2474 - val_loss: 0.4045 - val_mae: 0.2536 - learning_rate: 5.0000e-04\n","Epoch 24/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4132 - mae: 0.2593 - val_loss: 0.3914 - val_mae: 0.2531 - learning_rate: 5.0000e-04\n","Epoch 25/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3873 - mae: 0.2431 - val_loss: 0.3785 - val_mae: 0.2516 - learning_rate: 5.0000e-04\n","Epoch 26/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3870 - mae: 0.2587 - val_loss: 0.3665 - val_mae: 0.2517 - learning_rate: 5.0000e-04\n","Epoch 27/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3725 - mae: 0.2588 - val_loss: 0.3541 - val_mae: 0.2496 - learning_rate: 5.0000e-04\n","Epoch 28/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3576 - mae: 0.2523 - val_loss: 0.3428 - val_mae: 0.2496 - learning_rate: 5.0000e-04\n","Epoch 29/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3454 - mae: 0.2523 - val_loss: 0.3321 - val_mae: 0.2492 - learning_rate: 5.0000e-04\n","Epoch 30/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3353 - mae: 0.2502 - val_loss: 0.3209 - val_mae: 0.2474 - learning_rate: 5.0000e-04\n","Epoch 31/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3178 - mae: 0.2415 - val_loss: 0.3111 - val_mae: 0.2475 - learning_rate: 5.0000e-04\n","Epoch 32/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3086 - mae: 0.2434 - val_loss: 0.3011 - val_mae: 0.2471 - learning_rate: 5.0000e-04\n","Epoch 33/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3025 - mae: 0.2495 - val_loss: 0.2913 - val_mae: 0.2467 - learning_rate: 5.0000e-04\n","Epoch 34/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2922 - mae: 0.2439 - val_loss: 0.2823 - val_mae: 0.2470 - learning_rate: 5.0000e-04\n","Epoch 35/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2844 - mae: 0.2497 - val_loss: 0.2736 - val_mae: 0.2468 - learning_rate: 5.0000e-04\n","Epoch 36/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2699 - mae: 0.2356 - val_loss: 0.2651 - val_mae: 0.2465 - learning_rate: 5.0000e-04\n","Epoch 37/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2609 - mae: 0.2369 - val_loss: 0.2572 - val_mae: 0.2464 - learning_rate: 5.0000e-04\n","Epoch 38/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2551 - mae: 0.2407 - val_loss: 0.2493 - val_mae: 0.2459 - learning_rate: 5.0000e-04\n","Epoch 39/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2553 - mae: 0.2540 - val_loss: 0.2421 - val_mae: 0.2458 - learning_rate: 5.0000e-04\n","Epoch 40/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2390 - mae: 0.2437 - val_loss: 0.2347 - val_mae: 0.2457 - learning_rate: 5.0000e-04\n","Epoch 41/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2308 - mae: 0.2385 - val_loss: 0.2281 - val_mae: 0.2462 - learning_rate: 5.0000e-04\n","Epoch 42/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2282 - mae: 0.2406 - val_loss: 0.2218 - val_mae: 0.2462 - learning_rate: 5.0000e-04\n","Epoch 43/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2123 - mae: 0.2317 - val_loss: 0.2152 - val_mae: 0.2456 - learning_rate: 5.0000e-04\n","Epoch 44/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2132 - mae: 0.2418 - val_loss: 0.2088 - val_mae: 0.2453 - learning_rate: 5.0000e-04\n","Epoch 45/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2067 - mae: 0.2423 - val_loss: 0.2033 - val_mae: 0.2456 - learning_rate: 5.0000e-04\n","Epoch 46/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1995 - mae: 0.2412 - val_loss: 0.1977 - val_mae: 0.2457 - learning_rate: 5.0000e-04\n","Epoch 47/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1966 - mae: 0.2413 - val_loss: 0.1919 - val_mae: 0.2455 - learning_rate: 5.0000e-04\n","Epoch 48/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1830 - mae: 0.2306 - val_loss: 0.1867 - val_mae: 0.2452 - learning_rate: 5.0000e-04\n","Epoch 49/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1799 - mae: 0.2346 - val_loss: 0.1820 - val_mae: 0.2448 - learning_rate: 5.0000e-04\n","Epoch 50/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1798 - mae: 0.2415 - val_loss: 0.1771 - val_mae: 0.2447 - learning_rate: 5.0000e-04\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1774 - mae: 0.2432 \n","Test MAE: 0.24473564326763153\n","XGBoost MAE: 0.2505667621400293\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from xgboost import XGBRegressor\n","\n","# Load dataset\n","df = pd.read_csv(\"timing_performance_dataset.csv\")\n","\n","# Identify the correct target column\n","print(\"Dataset Columns:\", df.columns)  # Print column names to identify target\n","target_column = \"Timing_Violation_Probability\"  # Replace with the correct target column\n","\n","if target_column not in df.columns:\n","    raise KeyError(f\"Column '{target_column}' not found in dataset. Available columns: {df.columns}\")\n","\n","# Handle missing values\n","df.fillna(df.mean(), inplace=True)\n","\n","X = df.drop(columns=[target_column])\n","y = df[target_column]\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalize the dataset\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Build the Neural Network model\n","model = Sequential([\n","    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.2),\n","    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.2),\n","    Dense(1)\n","])\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=0.0005)\n","model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n","\n","# Callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n","\n","# Train the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, callbacks=[early_stopping, reduce_lr])\n","\n","# Evaluate the model\n","test_loss, test_mae = model.evaluate(X_test, y_test)\n","print(f\"Test MAE: {test_mae}\")\n","\n","# Alternative Model: XGBoost\n","xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.05, random_state=42)\n","xgb_model.fit(X_train, y_train)\n","\n","# Evaluate XGBoost model\n","xgb_predictions = xgb_model.predict(X_test)\n","xgb_mae = np.mean(np.abs(y_test - xgb_predictions))\n","print(f\"XGBoost MAE: {xgb_mae}\")\n"]}]}